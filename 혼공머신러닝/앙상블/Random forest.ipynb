{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정형 데이터와 비정현 데이터\n",
    "머신러닝 정형 데이터\n",
    "- 정형 데이터는 csv, 엑셀, 데이터베이스\n",
    "- 전처리 특성공학\n",
    "- 가장 뛰어난 성능은 트리 앙상블 모델\n",
    "- 랜덤 포레드슽, 그래디언트 부스팅\n",
    "딥러닝은 비정형 데이터\n",
    "- 비정형 데이터는 텍스트, 오디오, 이미지, 영상\n",
    "- 표현 학습\n",
    "\n",
    "\n",
    "### Random forest\n",
    "- 랜포는 다수의 결정 트리들을 학습하는 앙상블 방법\n",
    "- 부스트랩 샘플과 랜덤한 후보 특성들을 사용해 여러개의 결정 트리를 앙상블 시킴?\n",
    "- 훈련데이터에 오버피팅을 막아주고 모델의 일반화 성능이 항상 단일 트리보다 높음\n",
    "- 가장 큰 특징은 랜덤성애 의해 트리들이 서로 조금씩 다른 특성을 갖는다 == 노이즈에 강하다\n",
    "- 트리를 기본으로 100개\n",
    "\n",
    "훈련방법\n",
    "- 훈련세트 -> 랜덤 샘플링(중복 허용) -> 부트스트랩 샘플 -> 결정트리 훈련\n",
    "- 여기서 부트스트랩은 주어진 훈련데이터에서 중복을 허용하여  데이셋과 같은 크기의 데이터셋을 만드는 과정\n",
    "- 분류시 결정트리 훈련 결과 확률들을 더해 트리 개수로 나눔\n",
    "- 회귀시 결정트리 훈련 결과 예측값을 더해 트리 개수로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23167441, 0.50039841, 0.26792718])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2)\n",
    "\n",
    "# 램덤 포레스트\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# 교차검증한거\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
    "# print(rf.feature_importances_)\n",
    "\n",
    "# 교차 검증 하지 않고 훈련\n",
    "rf.fit(train_input, train_target)\n",
    "# rf.score(train_input, train_target), rf.score(test_input, test_target)\n",
    "\n",
    "rf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOB(Out Of Bagging)\n",
    "- 배깅은 bootstrap aggregating의 약자\n",
    "- 부트스트랩을 통해 조금씩 다른 훈련 데이터에 대해 훈련된 기초 분류기(base learner)들의 결합을 aggregating(집계) 시키는 방법\n",
    "- OOB는 부트스트랩을 통해 랜덤으로 중복 추출했을때, 훈련데이터에 속하지 않은 데이터를 말함\n",
    "- OOB 에러는 부트스트랩에 포함되지 않은 데이ㅓ를 결정 트리를 통해 나온 예측값과 실제 값의 차이 -> 랜덤포레스트 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934000384837406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOB(out-of-bagging를 검증세트로 활용\n",
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "\n",
    "rf.oob_score_\n",
    "# 검증 세트와 유사 - np.mean(scores['test_score']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1dd475f507be082ea69982e00ecc6e654061df2dada6490a6a8a603cd38e4e58"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
