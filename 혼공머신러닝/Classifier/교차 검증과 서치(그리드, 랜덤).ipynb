{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검증 세트 (Validation set), 개발세트\n",
    "- 모델 개발에 데이터를 training과 test set의 2개로 구분하여 사용\n",
    "- 그러나 이 경우 test set에 오버피팅이 될 가능성이 있음! -> 실전 테스트셋 필요\n",
    "- 교차 검증 과정`cross validataion`이 필요\n",
    "- test셋이 역할을 한 training 모델에 대한 최적의 하이퍼파라미터 찾기는 calidation세트가 맡고\n",
    "- test셋은 현장 데이터 역할을 함 \n",
    "- 3개의 데이터셋으로 구분하여 사용\n",
    "- 최적의 하이퍼파라미터를 찾은 후에는 80퍼로 최종 모델 생성 후 테스트한다\n",
    "\n",
    "### K- Fold 교차검증 Cross Validation\n",
    "- 데이터의 크기에 따라서 데이터셋(훈련, 검증, 테스트)크기는 조절 필요\n",
    "- 전체 데이터셋이 작은 경우, 검증 데이터에 별도 20% 할당이 부담스러움!\n",
    "- 모델 훈련시 일정 부분(fold)로 분할해서 훈련과 검증에 동시 사용(k-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8412558303102096"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
    "data = wine[['alcohol','sugar','pH']].to_numpy()\n",
    "target = wine['class'].to_numpy()\n",
    "\n",
    "\n",
    "# 훈련(검증), 테스트셋\n",
    "train_input, test_input, train_target, test_target = train_test_split(data, target, random_state=42, test_size=0.2)\n",
    "# 훈련, 검증셋\n",
    "sub_input, val_input, sub_target, val_target = train_test_split(train_input, train_target, random_state=42, test_size=0.2)\n",
    "\n",
    "# K-Fold 교차 검증\n",
    "dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt.fit(train_input, train_target)\n",
    "\n",
    "# 사이킷런 model_selection 밑에 교차검증\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(dt, train_input, train_target)\n",
    "scores\n",
    "\n",
    "# {'fit_time': array([0.00300026, 0.00299835, 0.00400233, 0.00303411, 0.00300026]),\n",
    "#  'score_time': array([0.        , 0.        , 0.        , 0.00100112, 0.00100803]),\n",
    "#  'test_score': array([0.84230769, 0.83365385, 0.84504331, 0.8373436 , 0.8479307 ])}\n",
    "\n",
    "# 검증 점수\n",
    "np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분할기 사용한 교차검증\n",
    "- fold 은 기본으로 5이고 \n",
    "- 분류모델은 `cv =StratifiedKFold()` 회귀모델은 `cv = Kfold()`\n",
    "- 분류모델은 cv에 설정을 하지 ㅇ낳아도 객체 따라서 자도으로 함수 선택사용 \n",
    "- cv 인자를 이용하여 원하는 개수로 설정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8335549132947977"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "scores = cross_validate(dt, train_input, train_target, cv = splitter)\n",
    "np.mean(scores['test_score'])\n",
    "# ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그리드 검색 (grid search)\n",
    "- 최적의 하이퍼파라미터를 찾기 위해 반복적으로 변경해가면서 실행\n",
    "- 여러개 매개변수가 있다면 조합이 급증 됨 -  max_depth, min_impurity_decrease등\n",
    "- 반복문을 이용해서 찾을 수도 있지만 그리드가 좀 더 편함\n",
    "- GridSearchCV 클래스는 교차검증을 하면서 하이퍼파라미터를 찾아준다\n",
    "- 파라미터는 딕셔너리로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86819297, 0.75793737, 0.86492226, 0.86780891, 0.86761605])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그리드 검색\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 매개변수에 노드를 분할하기 위한 불순도 최소량 값을 리스트로 지정\n",
    "params = {'min_impurity_decrease' : [0.0001, 000.2, 0.0003, 0.0004, 0.0005]}\n",
    "\n",
    "# 첫번째 인자는 클래스 객체, 기본이 5-fold이고 리스트에 5개 값이 5*5=25개 모델 생성됨, n_jobs는 core개수(-1은 모두 사용)\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs = -1)\n",
    "gs.fit(train_input, train_target)\n",
    "\n",
    "# 최적의 파라미터 저장\n",
    "dt = gs.best_estimator_\n",
    "# 최적의 파라미터로 훈련한 점수\n",
    "dt.score(train_input, train_target)\n",
    "\n",
    "# 최적의 파라미터 값\n",
    "gs.best_params_\n",
    "#0.001\n",
    "\n",
    "# 교차 검증\n",
    "gs.cv_results_['mean_test_score']\n",
    "# [0.86819297, 0.75793737, 0.86492226, 0.86780891, 0.86761605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여러개 파라미터 설정\n",
    "params ={ 'min_impurity_decrease' : np.arange(0.0001, 0.001, 0.0001), \n",
    "          'max_depth' : range(5,20,1),\n",
    "          'min_samples_split' : range(2,100,10)\n",
    "        }\n",
    "\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state =42), params, n_jobs=-1)\n",
    "gs.fit(train_input, train_target)\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 검색  - 확률 분포 선택\n",
    "- 랜덤서치를 사용하기 위해서는 scypy에 있는 확률 분포 클래스 사용\n",
    "- 그리드 서치는 일정 간격 샘플을 사용해 넓은 범위의 경우 많은 모델 생성\n",
    "- 랜덤서치는 랜덤 샘플을 이용해서 매개 변수로 이용할 것이기 때문에 균등 분포 랜덤값이 필요함\n",
    "  - 특히 매개변수가 실수일 경우에 더욱 필요\n",
    "- 균일(균등) 분포 샘플링 클래스 : 실수 uniform 정수 randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 검색\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# 정수 0~9\n",
    "rgen = randint(0,10)\n",
    "#rvs(random variable sampling) 10개 생성\n",
    "rgen.rvs(10)\n",
    "\n",
    "# 1000개 unique()발생히면 9개의 비슷한 수인 고유값 반환\n",
    "np.unique(rgen.rvs(1000), return_counts=True)\n",
    "\n",
    "ugen = uniform(0,1)\n",
    "ugen.rvs(10)\n",
    "\n",
    "\n",
    "# 딕셔너리로 매개 변수들의 번위 설정(실수, 정수)\n",
    "params = {'min_impurity_decrease': uniform(0.0001, 0.001),\n",
    "          'max_depth' : randint(20,50),\n",
    "          'min_samples_split' : randint(2,25),\n",
    "          'min_samples_leaf' : randint(1,25)\n",
    "          }\n",
    "\n",
    "# 랜럼 클래스는 교차 검증을 하면서 매개변수 찾음\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# n_iter는 파람스에서 샘플링 100개의 모델을 만듦\n",
    "gs = RandomizedSearchCV(DecisionTreeClassifier(random_state =42), params, n_iter=100, n_jobs=-1, random_state=42)\n",
    "gs.fit(train_input, train_target)\n",
    "\n",
    "gs.best_params_\n",
    "# {'max_depth': 39,\n",
    "#  'min_impurity_decrease': 0.00034102546602601173,\n",
    "#  'min_samples_leaf': 7,\n",
    "#  'min_samples_split': 13}\n",
    "\n",
    "# 훈련세트 평가 최대 점수\n",
    "np.max(gs.cv_results_['mean_test_score'])\n",
    "\n",
    "# 훈련세트 전체로 데이터 학습\n",
    "dt = gs.best_estimator_\n",
    "# 테스트 세트 평가\n",
    "dt.score(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884615384615384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 확인 문데\n",
    "# RandomizedSearchCV에서 디시전트 클래스에 splitter='random' 매개 변수를 추가하고 다시 훈련\n",
    "# Splitter 매개 변수 기본 값은 best로 각 노드에서 최선의 분할을 찾음\n",
    "# random으로 하면 무작위로 분할한 다음 가장 좋은 것을 고름\n",
    "# 테스트 세트 성능이 올라감?\n",
    "\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# 파람스 설정\n",
    "params = {'min_impurity_decrease': uniform(0.0001, 0.001),\n",
    "          'max_depth' : randint(20,50),\n",
    "          'min_samples_split' : randint(2,25),\n",
    "          'min_samples_leaf' : randint(1,25)\n",
    "          }\n",
    "\n",
    "# 랜덤서치 함수\n",
    "gs = RandomizedSearchCV(DecisionTreeClassifier(splitter ='random', random_state =42), params, n_jobs =-1, n_iter =100)\n",
    "gs.fit(train_input, train_target)\n",
    "\n",
    "# 베스트 파람스 확인\n",
    "gs.best_params_\n",
    "\n",
    "# 베스트인 얘들로 학습\n",
    "dt = gs.best_estimator_\n",
    "dt.score(test_input, test_target)\n",
    "# 떨어짐"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1dd475f507be082ea69982e00ecc6e654061df2dada6490a6a8a603cd38e4e58"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
